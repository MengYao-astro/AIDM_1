{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AiDM assignment 1\n",
    "## Recommender system --- 4 naive approaches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data\n",
    "We load the ratings data into a matrix which has 4 columns. The first column gives the user id. The second column gives the movie id. The third column gives the rating which can only be a integer from 1 to 5. The fourth column gives the timestamp in a unit of second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_origin = np.genfromtxt('ml-1m/ratings.dat', delimiter= '::')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First approach\n",
    "We define a function to calculate the mean of all ratings as a global rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_global(data):\n",
    "    R_global = np.mean(data[:,2])\n",
    "    return R_global"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second approach\n",
    "We define a funtion to calculate the mean rating of every user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_user(data):\n",
    "    user_list = np.unique(data[:,0]) # the user IDs will be automatically sorted with np.unique\n",
    "    R_user = np.zeros((len(user_list),2))\n",
    "    for i in range(len(user_list)):\n",
    "        # The rating data will be selected in order to calculte the average based on True/ Flase markers.\n",
    "        marker = data[:,0] == user_list[i]\n",
    "        R_user[i,0] = user_list[i]\n",
    "        R_user[i,1] = np.mean(data[marker][:,2])\n",
    "    return R_user # This array contains 2 columns which are user ID and mean ratings, repectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Third approach\n",
    "We define a function to calculate the mean rating of every movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_movie(data):\n",
    "    movie_list = np.unique(data[:,1]) # the movie IDs will be automatically sorted with np.unique\n",
    "    R_movie = np.zeros((len(movie_list),2))\n",
    "    for i in range(len(movie_list)):\n",
    "        # The rating data will be selected in order to calculte the average based on True/ Flase markers.\n",
    "        marker = data[:,1] == movie_list[i]  \n",
    "        R_movie[i,0] = movie_list[i]\n",
    "        R_movie[i,1] = np.mean(data[marker][:,2])\n",
    "    return R_movie # This array contains 2 columns which are movie ID and mean ratings, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fourth approach\n",
    "We define a function to calculate the estimated rating as a combination of mean of users and mean of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls(data):\n",
    "    INPUT=np.ones((len(data),3))\n",
    "    R_user = mean_user(data) # call the function mean_user\n",
    "    R_movie = mean_movie(data) # call the function mean_movie\n",
    "    for i in range(len(data)):\n",
    "        INPUT[i,0] = R_user[np.where(R_user[:,0]==data[i,0])[0][0],1]\n",
    "        INPUT[i,1] = R_movie[np.where(R_movie[:,0]==data[i,1])[0][0],1]\n",
    "    ls_para = np.linalg.lstsq(INPUT, data[:,2],rcond=None)\n",
    "    # This tuple mainly will provide us 2 informations, one is the coeffients and the other is the sum squared error.\n",
    "    return R_user, R_movie, ls_para"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply four approaches to the entire data\n",
    "We apply the approaches to the entire data and have the first look of the averages and the results of least square method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The global average of ratings is  3.581564453029317\n",
      "\n",
      " The average rating for each user with the user ID in the first column is \n",
      " [[1.00000000e+00 4.18867925e+00]\n",
      " [2.00000000e+00 3.71317829e+00]\n",
      " [3.00000000e+00 3.90196078e+00]\n",
      " ...\n",
      " [6.03800000e+03 3.80000000e+00]\n",
      " [6.03900000e+03 3.87804878e+00]\n",
      " [6.04000000e+03 3.57771261e+00]]\n",
      "\n",
      " The average rating for each movie with the movie ID in the first column is \n",
      " [[1.00000000e+00 4.14684641e+00]\n",
      " [2.00000000e+00 3.20114123e+00]\n",
      " [3.00000000e+00 3.01673640e+00]\n",
      " ...\n",
      " [3.95000000e+03 3.66666667e+00]\n",
      " [3.95100000e+03 3.90000000e+00]\n",
      " [3.95200000e+03 3.78092784e+00]]\n",
      "\n",
      " The alpha, beta, gamma values given by least square algorithm are \n",
      " [838481.41893202]\n",
      "Besides, the sum square error of least square method is  838481.4189320239\n"
     ]
    }
   ],
   "source": [
    "avg_global_origin = mean_global(data_origin)\n",
    "ls_result_origin = ls(data_origin)\n",
    "print('The global average of ratings is ', avg_global_origin)\n",
    "print('\\n The average rating for each user with the user ID in the first column is \\n', ls_result_origin[0])\n",
    "print('\\n The average rating for each movie with the movie ID in the first column is \\n',ls_result_origin[1])\n",
    "print('\\n The alpha, beta, gamma values given by least square algorithm are \\n', ls_result_origin[2][1])\n",
    "print('Besides, the sum square error of least square method is ', ls_result_origin[2][1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-fold Cross Validation\n",
    "We split your data into N parts and then develop N models on all combinations of (N-1) parts. At the end, we test our N models on test set and take the average of error over the number of test tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_4naive(data_all, N):\n",
    "    np.random.shuffle(data_all) # Note this only shuffles row order, individual user_id/movie_id/rate entries are the same\n",
    "    errors = np.zeros(4) # prepare a numpy array to return 4 errors made by 4 naive approaches \n",
    "    # The order will be: 'global', 'user', 'movie', 'least square method'\n",
    "    for i in range(N):\n",
    "        # drag out 1/N part of the entire data as a test set\n",
    "        data_test = data_all[int(i/N*len(data_all)):int(((i+1)/N)*len(data_all))]\n",
    "        # delete the test set from entire data and it gives us a training set as remaining.\n",
    "        data_folder = np.delete(data_all,np.s_[int(i/N*len(data_all)):int(((i+1)/N)*len(data_all))],0)\n",
    "        R_global = mean_global(data_folder)\n",
    "        # The final error provided would be sum(real rating-estimated rating)**2/ (number of ratings)\n",
    "        # and then take the average over the number of test sets\n",
    "        errors[0] += sum((data_test[:,2]-R_global)**2)/len(data_test)/N\n",
    "        '''\n",
    "        Then we do the other 3 naive approaches\n",
    "        '''\n",
    "        # first of all, we input the training folders and return the models of 3 approaches.\n",
    "        ls_result = ls(data_folder)\n",
    "        R_user = ls_result[0]\n",
    "        R_movie = ls_result[1]\n",
    "        ls_para = ls_result[2]\n",
    "        # prepare a numpy zeros array which contains the estimated ratings based on users and movies\n",
    "        # in the first and second column, respectively\n",
    "        rating_est = np.zeros((len(data_test),3))\n",
    "        for j in range(len(data_test)):\n",
    "            # In case any user in test set has not showed in the training set, \n",
    "            # we would like to use global average as an estimated rating.\n",
    "            try:\n",
    "                rating_est[j,0] = R_user[int(np.where(R_user[:,0]== data_test[j,0])[0][0]),1]\n",
    "            except:\n",
    "                rating_est[j,0] = R_global\n",
    "            # In case any movie in test set has not showed in the training set, \n",
    "            # we would like to use global average as an estimated rating.\n",
    "            try:\n",
    "                rating_est[j,1] = R_movie[int(np.where(R_movie[:,0]== data_test[j,1])[0][0]),1]\n",
    "            except:\n",
    "                rating_est[j,1] = R_global\n",
    "        rating_est[:,2] = ls_para[0][0]*rating_est[:,0] + ls_para[0][1]*rating_est[:,1] + ls_para[0][2]\n",
    "        errors[1] += sum((data_test[:,2]-rating_est[:,0])**2)/len(data_test)/N\n",
    "        errors[2] += sum((data_test[:,2]-rating_est[:,1])**2)/len(data_test)/N\n",
    "        errors[3] += sum((data_test[:,2]-rating_est[:,2])**2)/len(data_test)/N\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "In this part, we calculate the squared error per rating, which is to divide the sum squared error by the length of the test set and then take the average over the number of test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error for global average method is  1.2479161841688666\n",
      "error for user average method is  1.0723646943791647\n",
      "error for movie average method is  0.9589793230954573\n",
      "error for least square method is 0.8543680526172086\n"
     ]
    }
   ],
   "source": [
    "result = fold_4naive(data_origin,5)\n",
    "print('error for global average method is ', result[0])\n",
    "print('error for user average method is ', result[1])\n",
    "print('error for movie average method is ', result[2])\n",
    "print('error for least square method is', result[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "In this report, first of all, we managed the entire data set to show the global average rating and average rating of users and so on.\n",
    "Secondly, we applied N fold cross validation to each naive approach on the data set with N = 5. \n",
    "As we can see from the results, the global method's preformence is the worst and the combined linear regression method provides the best estimation among 4 naive approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
